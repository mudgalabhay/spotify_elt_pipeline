[2026-02-19T19:19:02.877+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2026-02-19T19:19:02.906+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: spotify_minio_to_snowflake_bronze.load_data manual__2026-02-19T19:18:54.155348+00:00 [queued]>
[2026-02-19T19:19:02.913+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: spotify_minio_to_snowflake_bronze.load_data manual__2026-02-19T19:18:54.155348+00:00 [queued]>
[2026-02-19T19:19:02.914+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2026-02-19T19:19:02.925+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): load_data> on 2026-02-19 19:18:54.155348+00:00
[2026-02-19T19:19:02.933+0000] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'spotify_minio_to_snowflake_bronze', 'load_data', 'manual__2026-02-19T19:18:54.155348+00:00', '--job-id', '21', '--raw', '--subdir', 'DAGS_FOLDER/minio_to_snowflake.py', '--cfg-path', '/tmp/tmpkjtmh47i']
[2026-02-19T19:19:02.937+0000] {standard_task_runner.py:91} INFO - Job 21: Subtask load_data
[2026-02-19T19:19:02.937+0000] {logging_mixin.py:188} WARNING - /home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py:62 DeprecationWarning: This process (pid=227) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2026-02-19T19:19:02.938+0000] {standard_task_runner.py:64} INFO - Started process 241 to run task
[2026-02-19T19:19:03.005+0000] {task_command.py:426} INFO - Running <TaskInstance: spotify_minio_to_snowflake_bronze.load_data manual__2026-02-19T19:18:54.155348+00:00 [running]> on host fdce163c0245
[2026-02-19T19:19:03.096+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='spotify_minio_to_snowflake_bronze' AIRFLOW_CTX_TASK_ID='load_data' AIRFLOW_CTX_EXECUTION_DATE='2026-02-19T19:18:54.155348+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2026-02-19T19:18:54.155348+00:00'
[2026-02-19T19:19:03.098+0000] {taskinstance.py:430} INFO - ::endgroup::
[2026-02-19T19:19:03.124+0000] {connection.py:408} INFO - Snowflake Connector for Python Version: 3.11.0, Python Version: 3.12.4, Platform: Linux-6.6.87.1-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2026-02-19T19:19:03.125+0000] {connection.py:1258} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2026-02-19T19:19:06.555+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2026-02-19T19:19:07.542+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2026-02-19T19:19:07.543+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/minio_to_snowflake.py", line 130, in load_to_snowflake
    cur.execute(f"USE DATABASE {SNOWFLAKE_DATABASE}")
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1080, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002043 (02000): 01c285e7-0107-d377-001a-cbe30012e06a: SQL compilation error:
Object does not exist, or operation cannot be performed.
[2026-02-19T19:19:07.559+0000] {taskinstance.py:1206} INFO - Marking task as UP_FOR_RETRY. dag_id=spotify_minio_to_snowflake_bronze, task_id=load_data, run_id=manual__2026-02-19T19:18:54.155348+00:00, execution_date=20260219T191854, start_date=20260219T191902, end_date=20260219T191907
[2026-02-19T19:19:07.574+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 21 for task load_data (002043 (02000): 01c285e7-0107-d377-001a-cbe30012e06a: SQL compilation error:
Object does not exist, or operation cannot be performed.; 241)
[2026-02-19T19:19:07.587+0000] {local_task_job_runner.py:243} INFO - Task exited with return code 1
[2026-02-19T19:19:07.607+0000] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2026-02-19T19:19:07.610+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
